[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=32   
subdivisions=8  
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.0000001
burn_in=1000
max_batches = 500200
policy=steps
steps=4000,7000
scales=.1,.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

#1th 3x3
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
group=32
activation=leaky
#1th 1x1
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=leaky

#2th 3x3
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
group=64
activation=leaky
#2th 1x1
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

#3th 3x3
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
group=128
activation=leaky
#3th 1x1
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

#4th 3x3
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
group=128
activation=leaky
#4th 1x1                                              
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

#5th 3x3
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
group=256
activation=leaky
#5th 1x1
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

#6th 3x3
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
group=256
activation=leaky
#6th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#7th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#7th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#8th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#8th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky


#9th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#9th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#10th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#10th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#11th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#11th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#12th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
group=512
activation=leaky
#12th 1x1
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=0
activation=leaky


#13th 3x3
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
group=1024
activation=leaky
#13th 1x1
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=0
activation=leaky

#######

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[route]
layers=-14

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=64
activation=leaky

[reorg]
stride=2

[route]
layers=-1,-4

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=125
activation=linear


[region]
anchors =  1.3221, 1.73145, 3.19275, 4.00944, 5.05587, 8.09892, 9.47112, 4.84053, 11.2364, 10.0071
bias_match=1
classes=20
coords=4
num=5
softmax=1
jitter=.3
rescore=1

object_scale=5
noobject_scale=1
class_scale=1
coord_scale=1

absolute=1
thresh = .6
random=1
